{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d11d631",
   "metadata": {},
   "source": [
    "# Title: **Write a Program to Implement Value and Policy Iteration in a Grid World**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36729eed",
   "metadata": {},
   "source": [
    "## Objective: To develop a Python program that demonstrates value and policy iteration techniques in a simple grid world environment, illustrating key concepts of reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834adde7",
   "metadata": {},
   "source": [
    "### Theory\n",
    "In reinforcement learning, value and policy iteration are two fundamental methods used to compute optimal policies given a model of the environment in the form of a Markov Decision Process (MDP). \n",
    "\n",
    "**Value Iteration** is a method of computing an optimal policy by iteratively improving the value function for each state. It involves updating the value of each state by considering the maximum expected utility achievable by performing each action available from that state.\n",
    "\n",
    "**Policy Iteration** involves two steps: policy evaluation, where the utility of following a current policy is calculated, and policy improvement, where the policy is improved by making it greedy with respect to the evaluated utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b041aa3",
   "metadata": {},
   "source": [
    "### Materials/Tools Required\n",
    "- Python 3.x installed on a computer\n",
    "- Python libraries: `numpy`\n",
    "- Text editor or Integrated Development Environment (IDE) such as PyCharm, Visual Studio Code, or Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e7f9f",
   "metadata": {},
   "source": [
    "### Procedure\n",
    "1. Install the required Python library using pip:\n",
    "   ```bash\n",
    "   pip install numpy\n",
    "   ```\n",
    "2. Open your Python development environment.\n",
    "3. Type the provided code into the editor.\n",
    "4. Save the file with a `.py` extension, for example, `grid_world_iterations.py`.\n",
    "5. Run the program and observe how value and policy iteration algorithms converge to the optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Python Program Code\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def value_iteration(states, actions, transition, reward, gamma=0.9, threshold=0.01):\n",
    "    V = np.zeros(len(states))\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            v = V[s]\n",
    "            V[s] = max(sum(transition[s][a][s_prime] * (reward[s_prime] + gamma * V[s_prime]) \n",
    "                           for s_prime in states) for a in actions)\n",
    "            delta = max(delta, abs(v - V[s]))\n",
    "        if delta < threshold:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_iteration(states, actions, transition, reward, gamma=0.9):\n",
    "    policy = np.zeros(len(states), dtype=int)\n",
    "    V = np.zeros(len(states))\n",
    "    while True:\n",
    "        # Policy evaluation\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for s in states:\n",
    "                v = V[s]\n",
    "                V[s] = sum(transition[s][policy[s]][s_prime] * (reward[s_prime] + gamma * V[s_prime]) \n",
    "                           for s_prime in states)\n",
    "                delta = max(delta, abs(v - V[s]))\n",
    "            if delta < 0.01:\n",
    "                break\n",
    "        \n",
    "        # Policy improvement\n",
    "        policy_stable = True\n",
    "        for s in states:\n",
    "            old_action = policy[s]\n",
    "            policy[s] = np.argmax([sum(transition[s][a][s_prime] * (reward[s_prime] + gamma * V[s_prime]) \n",
    "                                       for s_prime in states) for a in actions])\n",
    "            if old_action != policy[s]:\n",
    "                policy_stable = False\n",
    "        \n",
    "        if policy_stable:\n",
    "            break\n",
    "    return policy, V\n",
    "\n",
    "# Example setup for a simple 2x2 grid world\n",
    "states = np.arange(4)  # 0, 1, 2, 3\n",
    "actions = [0, 1]  # 0: up, 1: down (simplified for example)\n",
    "transition = np.zeros((4, 2, 4))  # simplified transitions\n",
    "reward = np.array([-1, -1, -1, 10])  # rewards for each state\n",
    "\n",
    "# Setting up some example transitions (simplified)\n",
    "transition[0, 0, 1] = 1\n",
    "transition[1, 1, 3] = 1\n",
    "transition[2, 0, 3] = 1\n",
    "transition[3, 1, 3] = 1\n",
    "\n",
    "gamma = 0.9  # Discount factor\n",
    "\n",
    "# Run value iteration\n",
    "values = value_iteration(states, actions, transition, reward, gamma)\n",
    "print(\"Value Function:\")\n",
    "print(values)\n",
    "\n",
    "# Run policy iteration\n",
    "policy, values = policy_iteration(states, actions, transition, reward, gamma)\n",
    "print(\"Optimal Policy and Value Function:\")\n",
    "print(\"Policy:\", policy)\n",
    "print(\"Values:\", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Observations\n",
    "- Observe the convergence of both value and policy iteration algorithms to the optimal policy and value function.\n",
    "- Note the differences in convergence speed and computational efficiency between the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e052626",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conclusion\n",
    "Value and policy iteration are powerful algorithms used to solve decision-making problems modeled as MDPs in reinforcement learning. They provide systematic approaches for calculating optimal policies that maximize the cumulative reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a11c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applications\n",
    "- Robotics navigation and path planning\n",
    "- Strategic game playing\n",
    "- Resource management and allocation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
